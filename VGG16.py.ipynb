{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.datasets import load_files\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import *\n",
    "\n",
    "train_path = './train'\n",
    "validate_path = './val'\n",
    "test_path = './test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 299\n",
    "epochs = 50\n",
    "learning_rate = 0.0001\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "train_num = 3790\n",
    "validation_num = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weights = os.path.join('', 'weights_vgg16.h5')\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                             vertical_flip=True,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3790 images belonging to 12 classes.\n",
      "Found 480 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(dim, dim),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validate_generator = datagen.flow_from_directory(\n",
    "    validate_path,\n",
    "    target_size=(dim, dim),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5, verbose=0),\n",
    "             ModelCheckpoint(weights, monitor='val_loss', save_best_only=True, verbose=1),\n",
    "             ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2, verbose=0, mode='auto', epsilon=0.0001,\n",
    "                               cooldown=0, min_lr=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = VGG16(input_shape=(dim, dim, 3), include_top=False, weights='imagenet', pooling='avg')\n",
    "x = base_model.output\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(12, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 2.4805 - acc: 0.1284Epoch 00000: val_loss improved from inf to 2.49579, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 448s - loss: 2.4801 - acc: 0.1282 - val_loss: 2.4958 - val_acc: 0.0833\n",
      "Epoch 2/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 2.2722 - acc: 0.2037Epoch 00001: val_loss improved from 2.49579 to 2.25233, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 441s - loss: 2.2712 - acc: 0.2043 - val_loss: 2.2523 - val_acc: 0.2479\n",
      "Epoch 3/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 1.7158 - acc: 0.4436Epoch 00002: val_loss improved from 2.25233 to 2.17907, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 439s - loss: 1.7140 - acc: 0.4444 - val_loss: 2.1791 - val_acc: 0.2562\n",
      "Epoch 4/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 1.1706 - acc: 0.6123Epoch 00003: val_loss improved from 2.17907 to 0.87429, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 438s - loss: 1.1701 - acc: 0.6121 - val_loss: 0.8743 - val_acc: 0.6813\n",
      "Epoch 5/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.7340 - acc: 0.7598Epoch 00004: val_loss improved from 0.87429 to 0.58711, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 437s - loss: 0.7340 - acc: 0.7602 - val_loss: 0.5871 - val_acc: 0.7688\n",
      "Epoch 6/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.5680 - acc: 0.8112Epoch 00005: val_loss improved from 0.58711 to 0.55715, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 437s - loss: 0.5683 - acc: 0.8114 - val_loss: 0.5571 - val_acc: 0.8063\n",
      "Epoch 7/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.4881 - acc: 0.8374Epoch 00006: val_loss improved from 0.55715 to 0.49985, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 436s - loss: 0.4865 - acc: 0.8381 - val_loss: 0.4998 - val_acc: 0.8187\n",
      "Epoch 8/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.4245 - acc: 0.8562Epoch 00007: val_loss improved from 0.49985 to 0.39717, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 436s - loss: 0.4239 - acc: 0.8562 - val_loss: 0.3972 - val_acc: 0.8646\n",
      "Epoch 9/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.3732 - acc: 0.8803Epoch 00008: val_loss did not improve\n",
      "237/236 [==============================] - 434s - loss: 0.3734 - acc: 0.8802 - val_loss: 0.4385 - val_acc: 0.8396\n",
      "Epoch 10/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.2845 - acc: 0.8980Epoch 00009: val_loss improved from 0.39717 to 0.37738, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 435s - loss: 0.2864 - acc: 0.8979 - val_loss: 0.3774 - val_acc: 0.8625\n",
      "Epoch 11/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.3081 - acc: 0.9028Epoch 00010: val_loss did not improve\n",
      "237/236 [==============================] - 434s - loss: 0.3091 - acc: 0.9029 - val_loss: 0.4012 - val_acc: 0.8667\n",
      "Epoch 12/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.2525 - acc: 0.9182Epoch 00011: val_loss did not improve\n",
      "237/236 [==============================] - 434s - loss: 0.2515 - acc: 0.9185 - val_loss: 0.4870 - val_acc: 0.8583\n",
      "Epoch 13/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.2777 - acc: 0.9086Epoch 00012: val_loss did not improve\n",
      "237/236 [==============================] - 433s - loss: 0.2778 - acc: 0.9084 - val_loss: 0.4526 - val_acc: 0.8458\n",
      "Epoch 14/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.2570 - acc: 0.9206Epoch 00013: val_loss improved from 0.37738 to 0.33048, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 435s - loss: 0.2563 - acc: 0.9209 - val_loss: 0.3305 - val_acc: 0.8875\n",
      "Epoch 15/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.2362 - acc: 0.9160Epoch 00014: val_loss did not improve\n",
      "237/236 [==============================] - 433s - loss: 0.2356 - acc: 0.9161 - val_loss: 0.3398 - val_acc: 0.8875\n",
      "Epoch 16/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.2181 - acc: 0.9266Epoch 00015: val_loss improved from 0.33048 to 0.30960, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 434s - loss: 0.2174 - acc: 0.9270 - val_loss: 0.3096 - val_acc: 0.8854\n",
      "Epoch 17/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.1930 - acc: 0.9356Epoch 00016: val_loss did not improve\n",
      "237/236 [==============================] - 433s - loss: 0.1923 - acc: 0.9359 - val_loss: 0.4269 - val_acc: 0.8792\n",
      "Epoch 18/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.1824 - acc: 0.9386Epoch 00017: val_loss did not improve\n",
      "237/236 [==============================] - 432s - loss: 0.1829 - acc: 0.9385 - val_loss: 0.6624 - val_acc: 0.8167\n",
      "Epoch 19/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.2004 - acc: 0.9349Epoch 00018: val_loss improved from 0.30960 to 0.29847, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 433s - loss: 0.2022 - acc: 0.9342 - val_loss: 0.2985 - val_acc: 0.8833\n",
      "Epoch 20/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.1622 - acc: 0.9454Epoch 00019: val_loss improved from 0.29847 to 0.25820, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 433s - loss: 0.1631 - acc: 0.9451 - val_loss: 0.2582 - val_acc: 0.9062\n",
      "Epoch 21/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.1602 - acc: 0.9473Epoch 00020: val_loss improved from 0.25820 to 0.22797, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 433s - loss: 0.1601 - acc: 0.9472 - val_loss: 0.2280 - val_acc: 0.9187\n",
      "Epoch 22/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.1589 - acc: 0.9497Epoch 00021: val_loss did not improve\n",
      "237/236 [==============================] - 431s - loss: 0.1584 - acc: 0.9499 - val_loss: 0.3367 - val_acc: 0.9125\n",
      "Epoch 23/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.1603 - acc: 0.9507Epoch 00022: val_loss did not improve\n",
      "237/236 [==============================] - 431s - loss: 0.1602 - acc: 0.9509 - val_loss: 0.2492 - val_acc: 0.9229\n",
      "Epoch 24/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.1383 - acc: 0.9563Epoch 00023: val_loss did not improve\n",
      "237/236 [==============================] - 431s - loss: 0.1380 - acc: 0.9565 - val_loss: 0.3085 - val_acc: 0.9021\n",
      "Epoch 25/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.1364 - acc: 0.9558Epoch 00024: val_loss did not improve\n",
      "237/236 [==============================] - 431s - loss: 0.1364 - acc: 0.9557 - val_loss: 0.2838 - val_acc: 0.9083\n",
      "Epoch 26/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.1888 - acc: 0.9441Epoch 00025: val_loss improved from 0.22797 to 0.18421, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 433s - loss: 0.1894 - acc: 0.9438 - val_loss: 0.1842 - val_acc: 0.9292\n",
      "Epoch 27/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.1162 - acc: 0.9603Epoch 00026: val_loss did not improve\n",
      "237/236 [==============================] - 431s - loss: 0.1174 - acc: 0.9598 - val_loss: 0.2082 - val_acc: 0.9375\n",
      "Epoch 28/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.2143 - acc: 0.9335Epoch 00027: val_loss did not improve\n",
      "237/236 [==============================] - 431s - loss: 0.2140 - acc: 0.9335 - val_loss: 0.2199 - val_acc: 0.9437\n",
      "Epoch 29/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.0984 - acc: 0.9709Epoch 00028: val_loss improved from 0.18421 to 0.16731, saving model to weights_vgg16.h5\n",
      "237/236 [==============================] - 433s - loss: 0.0987 - acc: 0.9707 - val_loss: 0.1673 - val_acc: 0.9563\n",
      "Epoch 30/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.0968 - acc: 0.9690Epoch 00029: val_loss did not improve\n",
      "237/236 [==============================] - 431s - loss: 0.0969 - acc: 0.9688 - val_loss: 0.2021 - val_acc: 0.9354\n",
      "Epoch 31/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.1146 - acc: 0.9640Epoch 00030: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/236 [==============================] - 431s - loss: 0.1142 - acc: 0.9641 - val_loss: 0.5219 - val_acc: 0.8750\n",
      "Epoch 32/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.1392 - acc: 0.9576Epoch 00031: val_loss did not improve\n",
      "237/236 [==============================] - 431s - loss: 0.1425 - acc: 0.9566 - val_loss: 0.3005 - val_acc: 0.9354\n",
      "Epoch 33/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.1668 - acc: 0.9534Epoch 00032: val_loss did not improve\n",
      "237/236 [==============================] - 432s - loss: 0.1664 - acc: 0.9536 - val_loss: 0.3468 - val_acc: 0.8833\n",
      "Epoch 34/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.0920 - acc: 0.9711Epoch 00033: val_loss did not improve\n",
      "237/236 [==============================] - 431s - loss: 0.0918 - acc: 0.9713 - val_loss: 0.2034 - val_acc: 0.9333\n",
      "Epoch 35/50\n",
      "236/236 [============================>.] - ETA: 1s - loss: 0.0644 - acc: 0.9807Epoch 00034: val_loss did not improve\n",
      "237/236 [==============================] - 431s - loss: 0.0644 - acc: 0.9807 - val_loss: 0.2174 - val_acc: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb1fdf569b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_num / batch_size,\n",
    "                    validation_data=validate_generator,\n",
    "                    validation_steps=validation_num/ batch_size,\n",
    "                    callbacks=callbacks,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 480 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weights = os.path.join('', 'weights_vgg16.h5')\n",
    "test_datagen = ImageDataGenerator()       \n",
    "generator_test = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(dim, dim),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,  \n",
    "    shuffle=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "30/30 [==============================] - 16s    \n"
     ]
    }
   ],
   "source": [
    "\n",
    "filenames = generator_test.filenames\n",
    "nb_samples = len(filenames)\n",
    "print(nb_samples)\n",
    "prediction_test = model.predict_generator(generator_test, verbose=1,steps =30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "480\n",
      "0.9604166666666667\n"
     ]
    }
   ],
   "source": [
    "prediction_list = []\n",
    "for i in range(len(prediction_test)):\n",
    "    result = np.argmax(prediction_test[i])\n",
    "    prediction_list.append(result)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(len(prediction_list)):\n",
    "    if prediction_list[i] == generator_test.classes[i]:\n",
    "        \n",
    "        count += 1\n",
    "print(count/480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
